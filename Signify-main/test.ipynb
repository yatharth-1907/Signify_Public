{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "left_model_filename = r'Models\\left_model.p'\n",
    "right_model_filename = r'Models\\right_model.p'\n",
    "pose_model_filename = r'Models\\pose_model.p'\n",
    "\n",
    "# Function to load a model from a pickle file\n",
    "def load_model(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        model_data = pickle.load(f)\n",
    "        return model_data['model']\n",
    "\n",
    "# Loading the pre-trained models\n",
    "left_model = load_model(left_model_filename)\n",
    "right_model = load_model(right_model_filename)\n",
    "pose_model = load_model(pose_model_filename)\n",
    "\n",
    "print(\"Models loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Mediapipe hands and pose solutions\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.7\n",
    ")\n",
    "pose = mp_pose.Pose(\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.7\n",
    ")\n",
    "\n",
    "# Define coordinate axes for angle calculations\n",
    "axes = {\n",
    "    \"x\": np.array([1, 0, 0]),\n",
    "    \"-x\": np.array([-1, 0, 0]),\n",
    "    \"y\": np.array([0, 1, 0]),\n",
    "    \"-y\": np.array([0, -1, 0]),\n",
    "    \"z\": np.array([0, 0, 1]),\n",
    "    \"-z\": np.array([0, 0, -1]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define coordinate axes for angle calculations\n",
    "\n",
    "def calculate_angle1(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Returns the cosine of the angle between vec1 and vec2.\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    # Prevent division by zero\n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0\n",
    "    cosine_angle = dot_product / (norm_vec1 * norm_vec2)\n",
    "    return cosine_angle\n",
    "\n",
    "def angle_between_vectors(v1, v2):\n",
    "    \"\"\"\n",
    "    Returns the angle in degrees between two vectors v1 and v2.\n",
    "    \"\"\"\n",
    "    dot_prod = np.dot(v1, v2)\n",
    "    mag_v1 = np.linalg.norm(v1)\n",
    "    mag_v2 = np.linalg.norm(v2)\n",
    "    # Clip cosine to avoid numerical issues\n",
    "    cos_theta = np.clip(dot_prod / (mag_v1 * mag_v2), -1.0, 1.0)\n",
    "    return np.degrees(np.arccos(cos_theta))\n",
    "\n",
    "def get_coordinates_safe(landmarks, index):\n",
    "    \"\"\"\n",
    "    Returns the x, y, z coordinates of a landmark; returns [-1, -1, -1] if not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return np.array([landmarks[index].x, landmarks[index].y, landmarks[index].z])\n",
    "    except IndexError:\n",
    "        return np.array([-1, -1, -1])\n",
    "\n",
    "def get_palm_orientation(normal):\n",
    "    \"\"\"\n",
    "    Determines which axis the palm's normal vector is closest to.\n",
    "    \"\"\"\n",
    "    angles = {axis: angle_between_vectors(normal, direction) for axis, direction in axes.items()}\n",
    "    # Return the axis with the smallest angle\n",
    "    best_match_axis = min(angles, key=angles.get)\n",
    "    return best_match_axis\n",
    "\n",
    "def extract_features(hand_landmarks, pose_landmarks=None):\n",
    "    \"\"\"\n",
    "    Gathers features from hand landmarks (finger angles, normal vector angles, distances to nose).\n",
    "    If pose_landmarks are provided, extracts wrist-nose distances as well.\n",
    "    \"\"\"\n",
    "    # Pairs of landmarks for finger angles\n",
    "    hand_pairs = [\n",
    "        (1, 3),   # Thumb\n",
    "        (6, 8),   # Index finger\n",
    "        (10, 12), # Middle finger\n",
    "        (14, 16), # Ring finger\n",
    "        (18, 20), # Pinky finger\n",
    "        (0, 9)    # Palm direction\n",
    "    ]\n",
    "    \n",
    "    features = []\n",
    "    # Compute angles for finger segments\n",
    "    for pair in hand_pairs:\n",
    "        lm1, lm2 = hand_landmarks[pair[0]], hand_landmarks[pair[1]]\n",
    "        vec = np.array([lm2.x - lm1.x, lm2.y - lm1.y, lm2.z - lm1.z])\n",
    "        \n",
    "        angle_x = calculate_angle1(vec, np.array([1, 0, 0]))\n",
    "        angle_y = calculate_angle1(vec, np.array([0, 1, 0]))\n",
    "        angle_z = calculate_angle1(vec, np.array([0, 0, 1]))\n",
    "        \n",
    "        features.extend([angle_x, angle_y, angle_z])\n",
    "    \n",
    "    # Vectors for palm normal\n",
    "    vector_0_to_5 = get_coordinates_safe(hand_landmarks, 5) - get_coordinates_safe(hand_landmarks, 0)\n",
    "    vector_0_to_17 = get_coordinates_safe(hand_landmarks, 17) - get_coordinates_safe(hand_landmarks, 0)\n",
    "    normal_vector = np.cross(vector_0_to_5, vector_0_to_17)\n",
    "    \n",
    "    # Angles between normal vector and coordinate axes\n",
    "    normal_angle_x = calculate_angle1(normal_vector, np.array([1, 0, 0]))\n",
    "    normal_angle_y = calculate_angle1(normal_vector, np.array([0, 1, 0]))\n",
    "    normal_angle_z = calculate_angle1(normal_vector, np.array([0, 0, 1]))\n",
    "    features.extend([normal_angle_x, normal_angle_y, normal_angle_z])\n",
    "    \n",
    "    # Distance from wrist (landmark 0) to nose (pose landmark 0)\n",
    "    if pose_landmarks is not None:\n",
    "        nose_landmark = get_coordinates_safe(pose_landmarks, 0)\n",
    "        wrist_landmark = get_coordinates_safe(hand_landmarks, 0)\n",
    "        distance_x = abs(nose_landmark[0] - wrist_landmark[0])\n",
    "        distance_y = abs(nose_landmark[1] - wrist_landmark[1])\n",
    "        features.extend([distance_x, distance_y])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_normal_safe(p1, p2, p3):\n",
    "    \"\"\"\n",
    "    Calculates the normal of the plane formed by three points (p1, p2, p3).\n",
    "    Returns [-1, -1, -1] if any point is invalid.\n",
    "    \"\"\"\n",
    "    if any(np.array_equal(pt, [-1, -1, -1]) for pt in [p1, p2, p3]):\n",
    "        return np.array([-1, -1, -1])\n",
    "    return calculate_normal(p1, p2, p3)\n",
    "\n",
    "def calculate_angle2(p1, p2, p3):\n",
    "    \"\"\"\n",
    "    Calculates the cosine of the angle at p2 formed by the vectors p1->p2 and p3->p2.\n",
    "    \"\"\"\n",
    "    v1 = p1 - p2\n",
    "    v2 = p3 - p2\n",
    "    if np.linalg.norm(v1) == 0 or np.linalg.norm(v2) == 0:\n",
    "        return -1\n",
    "    cos_theta = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    return cos_theta\n",
    "\n",
    "def calculate_normal(p1, p2, p3):\n",
    "    \"\"\"\n",
    "    Calculates and returns the normalized cross-product-based normal of the plane \n",
    "    formed by points p1, p2, and p3.\n",
    "    \"\"\"\n",
    "    v1 = p2 - p1\n",
    "    v2 = p3 - p1\n",
    "    normal = np.cross(v1, v2)\n",
    "    norm_val = np.linalg.norm(normal)\n",
    "    if norm_val == 0:\n",
    "        return np.array([-1, -1, -1])\n",
    "    return normal / norm_val\n",
    "\n",
    "def calculate_normal_angles(normal):\n",
    "    \"\"\"\n",
    "    Returns a list of dot products (cosine values) between the normal vector \n",
    "    and each axis in the identity matrix (x, y, z).\n",
    "    \"\"\"\n",
    "    cos_values = []\n",
    "    for axis in np.eye(3):\n",
    "        cos_values.append(np.dot(normal, axis))\n",
    "    return cos_values\n",
    "\n",
    "def calculate_xy_distance(p1, p2):\n",
    "    \"\"\"\n",
    "    Calculates and returns the absolute differences in x and y coordinates \n",
    "    between two points p1 and p2.\n",
    "    \"\"\"\n",
    "    x_distance = abs(p1[0] - p2[0])\n",
    "    y_distance = abs(p1[1] - p2[1])\n",
    "    return x_distance, y_distance\n",
    "\n",
    "def extract_pose_features(image, landmarks):\n",
    "    \"\"\"\n",
    "    Extracts pose features related to angles formed by specific joints, \n",
    "    normal vectors, and distances between landmarks in a pose.\n",
    "    \n",
    "    Parameters:\n",
    "        image      - The original image frame (unused here, but can be useful for display/logging).\n",
    "        landmarks  - List or array of pose landmarks from a Mediapipe result.\n",
    "        \n",
    "    Returns:\n",
    "        A list of feature values including:\n",
    "          - Cosine of joint angles.\n",
    "          - Normal vector angles with global axes.\n",
    "          - Distance between certain landmarks.\n",
    "    \"\"\"\n",
    "    # Define relevant point sets for angles and normals\n",
    "    points_sets = {\n",
    "        \"angle_11_12_14\": (get_coordinates_safe(landmarks, 11),\n",
    "                           get_coordinates_safe(landmarks, 12),\n",
    "                           get_coordinates_safe(landmarks, 14)),\n",
    "        \"angle_12_14_16\": (get_coordinates_safe(landmarks, 12),\n",
    "                           get_coordinates_safe(landmarks, 11),\n",
    "                           get_coordinates_safe(landmarks, 13)),\n",
    "        \"angle_11_13_15\": (get_coordinates_safe(landmarks, 11),\n",
    "                           get_coordinates_safe(landmarks, 13),\n",
    "                           get_coordinates_safe(landmarks, 15)),\n",
    "        \"angle_13_15_17\": (get_coordinates_safe(landmarks, 12),\n",
    "                           get_coordinates_safe(landmarks, 14),\n",
    "                           get_coordinates_safe(landmarks, 16)),\n",
    "        \"normal_1\":       (get_coordinates_safe(landmarks, 15),\n",
    "                           get_coordinates_safe(landmarks, 17),\n",
    "                           get_coordinates_safe(landmarks, 19)),\n",
    "        \"normal_2\":       (get_coordinates_safe(landmarks, 16),\n",
    "                           get_coordinates_safe(landmarks, 18),\n",
    "                           get_coordinates_safe(landmarks, 20))\n",
    "    }\n",
    "\n",
    "    angles = []\n",
    "    # Calculate angles for specified joints\n",
    "    for key, (p1, p2, p3) in points_sets.items():\n",
    "        if key.startswith(\"angle\"):\n",
    "            angles.append(calculate_angle2(p1, p2, p3))\n",
    "\n",
    "    # Calculate normals and their angles with the axes\n",
    "    for key, (p1, p2, p3) in points_sets.items():\n",
    "        if key.startswith(\"normal\"):\n",
    "            normal = calculate_normal_safe(p1, p2, p3)\n",
    "            if np.array_equal(normal, [-1, -1, -1]):\n",
    "                angles.extend([-1, -1, -1])\n",
    "            else:\n",
    "                angles.extend(calculate_normal_angles(normal))\n",
    "\n",
    "    # Distance between wrists (landmarks 15 and 16)\n",
    "    p15 = get_coordinates_safe(landmarks, 15)\n",
    "    p16 = get_coordinates_safe(landmarks, 16)\n",
    "    x_distance, y_distance = calculate_xy_distance(p15, p16)\n",
    "    angles.extend([x_distance, y_distance])\n",
    "\n",
    "    return angles\n",
    "\n",
    "def calulating_percentage(avg, all_classes):\n",
    "    \"\"\"\n",
    "    Given a list of average probabilities (avg) and corresponding class labels (all_classes),\n",
    "    returns a list of percentage values adjusted by class-specific thresholds.\n",
    "    \"\"\"\n",
    "    individual_threshold = {\n",
    "        \"sun\": 0.9, \"help\": 0.9, \"teacher\": 0.9, \"support\": 0.9,\n",
    "        \"paper\": 0.9, \"love\": 0.9, \"dance\": 0.9, \"water\": 0.9,\n",
    "        \"accident\": 0.9, \"yes\": 0.9, \"thick\": 0.9, \"high\": 0.9,\n",
    "        \"poor\": 0.9, \"i\": 0.9, \"my\": 0.9, \"important_1\": 0.9,\n",
    "        \"important_2\": 0.9, \"deaf\": 0.9, \"winner\": 0.9, \"eat\": 0.9,\n",
    "        \"pizza\": 0.9, \"go\": 0.9, \"isl\": 0.9, \"friend\": 0.9,\n",
    "        \"school\": 0.9, \"deep\": 0.9, \"loud\": 0.9, \"flat\": 0.9,\n",
    "        \"slow\": 0.9, \"sad\": 0.9, \"soft\": 0.9, \"happy\": 0.9,\n",
    "        \"poot\": 0.9, \"quiet\": 0.9, \"book\": 0.9, \"woman\": 0.9\n",
    "    }\n",
    "\n",
    "    threshold_percentage = []\n",
    "    for score, cls in zip(avg, all_classes):\n",
    "        # Use class-specific threshold to adjust the final percentage\n",
    "        threshold_val = individual_threshold.get(cls.lower(), 1.0)\n",
    "        threshold_percentage.append(score * 100 / threshold_val)\n",
    "\n",
    "    return threshold_percentage\n",
    "\n",
    "# Helper function to get landmark coordinates\n",
    "def get_coordinates_safe(landmarks, index):\n",
    "    \"\"\"\n",
    "    Retrieves the x, y, z coordinates of a given landmark index; \n",
    "    returns [-1, -1, -1] if the index is invalid.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return np.array([landmarks[index].x, landmarks[index].y, landmarks[index].z])\n",
    "    except (IndexError, AttributeError):\n",
    "        return np.array([-1, -1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track the number of frames, accumulated probabilities, and final drawn prediction\n",
    "frame_count = 0\n",
    "accumulated_probs = None\n",
    "final_prediction_text = \"\"\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture a frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Prepare the frame for Mediapipe\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image_rgb)\n",
    "    results_pose = pose.process(image_rgb)\n",
    "\n",
    "    # Initialize prediction outputs\n",
    "    left_prediction, right_prediction, pose_prediction = None, None, None\n",
    "    left_probs, right_probs, pose_probs = None, None, None\n",
    "\n",
    "    # Detect and process hand landmarks (up to two hands)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
    "            label = handedness.classification[0].label\n",
    "            features = extract_features(\n",
    "                hand_landmarks.landmark,\n",
    "                results_pose.pose_landmarks.landmark if results_pose.pose_landmarks else []\n",
    "            )\n",
    "\n",
    "            # Classify left or right hand\n",
    "            if label == 'Left':\n",
    "                left_prediction = left_model.predict([features])[0]\n",
    "                left_probs = left_model.predict_proba([features])[0]\n",
    "            elif label == 'Right':\n",
    "                right_prediction = right_model.predict([features])[0]\n",
    "                right_probs = right_model.predict_proba([features])[0]\n",
    "\n",
    "            # Draw hand landmarks on the frame\n",
    "            mp.solutions.drawing_utils.draw_landmarks(\n",
    "                frame, hand_landmarks, mp.solutions.hands.HAND_CONNECTIONS\n",
    "            )\n",
    "\n",
    "    # Detect and process pose landmarks\n",
    "    if results_pose.pose_landmarks:\n",
    "        mp.solutions.drawing_utils.draw_landmarks(\n",
    "            frame, results_pose.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS\n",
    "        )\n",
    "        pose_landmarks = results_pose.pose_landmarks.landmark\n",
    "        pose_features = extract_pose_features(frame, pose_landmarks)\n",
    "        pose_prediction = pose_model.predict([pose_features])[0]\n",
    "        pose_probs = pose_model.predict_proba([pose_features])[0]\n",
    "\n",
    "    # Gather all class labels used by the three models\n",
    "    all_classes = sorted(\n",
    "        set(left_model.classes_).union(\n",
    "            set(right_model.classes_)\n",
    "        ).union(\n",
    "            set(pose_model.classes_)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Align probabilities with the master list of classes\n",
    "    left_probs_aligned = np.zeros(len(all_classes))\n",
    "    right_probs_aligned = np.zeros(len(all_classes))\n",
    "    pose_probs_aligned = np.zeros(len(all_classes))\n",
    "\n",
    "    if left_probs is not None:\n",
    "        left_dict = dict(zip(left_model.classes_, left_probs))\n",
    "        left_probs_aligned = np.array([left_dict.get(cls, 0) for cls in all_classes]) * 100\n",
    "\n",
    "    if right_probs is not None:\n",
    "        right_dict = dict(zip(right_model.classes_, right_probs))\n",
    "        right_probs_aligned = np.array([right_dict.get(cls, 0) for cls in all_classes]) * 100\n",
    "\n",
    "    if pose_probs is not None:\n",
    "        pose_dict = dict(zip(pose_model.classes_, pose_probs))\n",
    "        pose_probs_aligned = np.array([pose_dict.get(cls, 0) for cls in all_classes]) * 100\n",
    "\n",
    "    # Determine the number of available sources (hand(s)/pose)\n",
    "    num_sources = sum(prob is not None for prob in [left_probs, right_probs, pose_probs])\n",
    "    # Average the probabilities (divide by 100 × num_sources to keep scale consistent)\n",
    "    avg = (left_probs_aligned + right_probs_aligned + pose_probs_aligned) / (100 * num_sources if num_sources else 1)\n",
    "\n",
    "    # Convert these averages into final percentages based on custom thresholds\n",
    "    avg_probs = calulating_percentage(avg, all_classes)\n",
    "\n",
    "    if accumulated_probs is None:\n",
    "        accumulated_probs = np.zeros_like(avg_probs)\n",
    "    accumulated_probs += avg_probs\n",
    "    frame_count += 1\n",
    "\n",
    "    # Updating the final prediction text after a fixed no. of frames (e.g., 5)\n",
    "    if frame_count == 5:\n",
    "        max_idx = np.argmax(accumulated_probs)\n",
    "        max_class = all_classes[max_idx]\n",
    "        final_prediction_text = f\"Final Prediction: {max_class}, Prob: {accumulated_probs[max_idx]:.2f}\"\n",
    "        accumulated_probs = None\n",
    "        frame_count = 0\n",
    "\n",
    "    if final_prediction_text:\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            final_prediction_text,\n",
    "            (10, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1,\n",
    "            (255, 0, 0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "    # Visualizing the accumulated probabilities on the screen\n",
    "    if accumulated_probs is not None:\n",
    "        y_offset = 60\n",
    "        for i, prob in enumerate(accumulated_probs):\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f\"{all_classes[i]}: {prob:.2f}\",\n",
    "                (10, y_offset),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.8,\n",
    "                (0, 0, 255),\n",
    "                2\n",
    "            )\n",
    "            y_offset += 30\n",
    "\n",
    "    cv2.imshow(\"Hand and Pose Tracking\", frame)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signify-sY8p2qH8-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
