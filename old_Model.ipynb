{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\swast\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.5.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained models from pick-le files\n",
    "left_model_filename = r'Models\\left.p'\n",
    "right_model_filename = r'Models\\right.p'\n",
    "pose_model_filename = r'Models\\pose.p'\n",
    "\n",
    "with open(left_model_filename, 'rb') as f:\n",
    "    left_model_data = pickle.load(f)\n",
    "    left_model = left_model_data['model']  # Adjust if the key for the model is different\n",
    "\n",
    "with open(right_model_filename, 'rb') as f:\n",
    "    right_model_data = pickle.load(f)\n",
    "    right_model = right_model_data['model']  # Adjust if the key for the model is different\n",
    "\n",
    "with open(pose_model_filename, 'rb') as f:\n",
    "    pose_model_data = pickle.load(f)\n",
    "    pose_model = pose_model_data['model']  # Adjust if the key for the model is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize hand extraction functions\n",
    "# Initialize Mediapipe hands detector\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "hands = mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "\n",
    "\n",
    "# Function to calculate the angle between two vectors\n",
    "def calculate_angle1(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    cosine_angle = dot_product / (norm_vec1 * norm_vec2)\n",
    "    # angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "    return cosine_angle  # Convert the angle from radians to degrees\n",
    "\n",
    "def get_coordinates_safe(landmark, index):\n",
    "    try:\n",
    "        return np.array([landmark[index].x, landmark[index].y, landmark[index].z])\n",
    "    except IndexError:\n",
    "        return np.array([-1, -1, -1])  # Return default values (e.g., [-1, -1, -1]) if landmark is not found\n",
    "\n",
    "axes = {\n",
    "    \"x\": np.array([1, 0, 0]),\n",
    "    \"-x\": np.array([-1, 0, 0]),\n",
    "    \"y\": np.array([0, 1, 0]),\n",
    "    \"-y\": np.array([0, -1, 0]),\n",
    "    \"z\": np.array([0, 0, 1]),\n",
    "    \"-z\": np.array([0, 0, -1]),\n",
    "}  \n",
    "\n",
    "def angle_between_vectors(v1, v2):\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    magnitude_v1 = np.linalg.norm(v1)\n",
    "    magnitude_v2 = np.linalg.norm(v2)\n",
    "    cos_theta = dot_product / (magnitude_v1 * magnitude_v2)\n",
    "    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n",
    "    theta = np.arccos(cos_theta)\n",
    "    return np.degrees(theta)\n",
    "\n",
    "# Function to classify palm orientation\n",
    "def get_palm_orientation(normal):\n",
    "    angles = {axis: angle_between_vectors(normal, direction) for axis, direction in axes.items()}\n",
    "    # Find the axis with the smallest angle\n",
    "    best_match_axis = min(angles, key=angles.get)\n",
    "    return best_match_axis\n",
    "\n",
    "\n",
    "# Function to extract hand features (angles between vectors and axes)\n",
    "def extract_features(hand_landmarks, pose_landmarks=None):\n",
    "    hand_pairs = [\n",
    "        (1, 3),  # Thumb\n",
    "        (6, 8),  # Index finger\n",
    "        (10, 12),  # Middle finger\n",
    "        (14, 16),  # Ring finger\n",
    "        (18, 20),  # Pinky finger\n",
    "        (0, 9)  # Palm direction\n",
    "    ]\n",
    "    \n",
    "    features = []\n",
    "    for pair in hand_pairs:\n",
    "        landmark1 = hand_landmarks[pair[0]]\n",
    "        landmark2 = hand_landmarks[pair[1]]\n",
    "        \n",
    "        vector = np.array([landmark2.x - landmark1.x, landmark2.y - landmark1.y, landmark2.z - landmark1.z])\n",
    "        x_axis = np.array([1, 0, 0])\n",
    "        y_axis = np.array([0, 1, 0])\n",
    "        z_axis = np.array([0, 0, 1])\n",
    "        \n",
    "        angle_x = calculate_angle1(vector, x_axis)\n",
    "        angle_y = calculate_angle1(vector, y_axis)\n",
    "        angle_z = calculate_angle1(vector, z_axis)\n",
    "        \n",
    "        features.extend([angle_x, angle_y, angle_z])\n",
    "    \n",
    "    # Safe access to landmarks for 0, 5, and 17\n",
    "    vector_0_to_5 = get_coordinates_safe(hand_landmarks, 5) - get_coordinates_safe(hand_landmarks, 0)\n",
    "    vector_0_to_17 = get_coordinates_safe(hand_landmarks, 17) - get_coordinates_safe(hand_landmarks, 0)\n",
    "    \n",
    "    normal_vector = np.cross(vector_0_to_5, vector_0_to_17)\n",
    "    \n",
    "    normal_angle_x = calculate_angle1(normal_vector, x_axis)\n",
    "    normal_angle_y = calculate_angle1(normal_vector, y_axis)\n",
    "    normal_angle_z = calculate_angle1(normal_vector, z_axis)\n",
    "    \n",
    "    features.extend([normal_angle_x, normal_angle_y, normal_angle_z])\n",
    "    \n",
    "    # If pose landmarks are available, calculate the distance between nose and wrist\n",
    "    \n",
    "    nose_landmark = get_coordinates_safe(pose_landmarks, 0)  # Nose is at index 0 in pose landmarks\n",
    "    wrist_landmark = get_coordinates_safe(hand_landmarks, 0)  # Wrist is at index 0 in hand landmarks\n",
    "        \n",
    "    # Calculate the distance in the x and y axes\n",
    "    distance_x = abs(nose_landmark[0] - wrist_landmark[0])\n",
    "    distance_y = abs(nose_landmark[1] - wrist_landmark[1])\n",
    "        \n",
    "    # Append the x and y distances as new features\n",
    "    features.extend([distance_x, distance_y])\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Initialize video capture (webcam feed)\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize pose extraction functions\n",
    "def calculate_normal_safe(p1, p2, p3):\n",
    "    # Check if any of the points is [-1, -1, -1] (default value for missing landmarks)\n",
    "    if np.array_equal(p1, [-1, -1, -1]) or np.array_equal(p2, [-1, -1, -1]) or np.array_equal(p3, [-1, -1, -1]):\n",
    "        return np.array([-1, -1, -1])  # Return [-1, -1, -1] if any point is missing\n",
    "    else:\n",
    "        return calculate_normal(p1, p2, p3)  # Otherwise, calculate the normal as usual\n",
    "        \n",
    "# Function to calculate angle between three points\n",
    "def calculate_angle2(p1, p2, p3):\n",
    "    # Create vectors from points p1, p2, p3\n",
    "    v1 = p1 - p2\n",
    "    v2 = p3 - p2\n",
    "    \n",
    "    # Calculate the cosine of the angle using dot product\n",
    "    cos_theta = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    angle = cos_theta\n",
    "    \n",
    "    return cos_theta\n",
    "\n",
    "# Function to calculate the normal of the plane formed by three points\n",
    "def calculate_normal(p1, p2, p3):\n",
    "    # Vectors on the plane\n",
    "    v1 = p2 - p1\n",
    "    v2 = p3 - p1\n",
    "    \n",
    "    # Cross product gives the normal vector\n",
    "    normal = np.cross(v1, v2)\n",
    "    \n",
    "    # Normalize the normal vector\n",
    "    normal = normal / np.linalg.norm(normal)\n",
    "    \n",
    "    return normal\n",
    "\n",
    "# Function to calculate the angle between the normal and each of the axes\n",
    "def calculate_normal_angles(normal):\n",
    "    # Calculate angles with x, y, z axes\n",
    "    cos_values = []\n",
    "    for axis in np.eye(3):  # x, y, z unit vectors\n",
    "        cos_value = np.dot(normal, axis)\n",
    "        cos_values.append(cos_value)\n",
    "    return cos_values\n",
    "\n",
    "# Function to calculate the x and y distance between two points\n",
    "def calculate_xy_distance(p1, p2):\n",
    "    x_distance = abs(p1[0] - p2[0])  # x-coordinate distance\n",
    "    y_distance = abs(p1[1] - p2[1])  # y-coordinate distance\n",
    "    return x_distance, y_distance\n",
    "\n",
    "\n",
    "# Function to extract the pose features\n",
    "def extract_pose_features(image, landmarks):\n",
    "    # Define the landmark indices for the required sets of points (using Pose landmark indices)\n",
    "    points_sets = {\n",
    "        \"angle_11_12_14\": (get_coordinates_safe(landmarks, 11), get_coordinates_safe(landmarks, 12), get_coordinates_safe(landmarks, 14)),  # Left shoulder, right shoulder, right elbow\n",
    "        \"angle_12_14_16\": (get_coordinates_safe(landmarks, 12), get_coordinates_safe(landmarks, 11), get_coordinates_safe(landmarks, 13)),  # Right shoulder, right elbow, right wrist\n",
    "        \"angle_11_13_15\": (get_coordinates_safe(landmarks, 11), get_coordinates_safe(landmarks, 13), get_coordinates_safe(landmarks, 15)),  # Left shoulder, left elbow, left wrist\n",
    "        \"angle_13_15_17\": (get_coordinates_safe(landmarks, 12), get_coordinates_safe(landmarks, 14), get_coordinates_safe(landmarks, 16)),  # Left elbow, left wrist, left hand\n",
    "        \"normal_1\": (get_coordinates_safe(landmarks, 15), get_coordinates_safe(landmarks, 17), get_coordinates_safe(landmarks, 19)),  # Plane formed by left shoulder, left hip, left knee\n",
    "        \"normal_2\": (get_coordinates_safe(landmarks, 16), get_coordinates_safe(landmarks, 18), get_coordinates_safe(landmarks, 20))   # Plane formed by right shoulder, right hip, right knee\n",
    "    }\n",
    "\n",
    "    # Calculate the angles between the specific sets of points\n",
    "    angles = []\n",
    "    for key, (p1, p2, p3) in points_sets.items():\n",
    "        if key.startswith(\"angle\"):\n",
    "            angle = calculate_angle2(p1, p2, p3)\n",
    "            angles.append(angle)\n",
    "    \n",
    "    # Calculate normals and angles with axes\n",
    "    for key, (p1, p2, p3) in points_sets.items():\n",
    "        if key.startswith(\"normal\"):\n",
    "            normal = calculate_normal_safe(p1, p2, p3)  # Safe normal calculation\n",
    "            if np.array_equal(normal, [-1, -1, -1]):\n",
    "                # If normal is [-1, -1, -1], it indicates missing points, so append [-1, -1, -1] for each axis angle\n",
    "                angles.extend([-1, -1, -1])\n",
    "            else:\n",
    "                normal_angles = calculate_normal_angles(normal)\n",
    "                angles.extend(normal_angles)  # Append angles with x, y, z axes\n",
    "\n",
    "    # Add the distance between points 15 (left wrist) and 16 (right wrist)\n",
    "    p15 = get_coordinates_safe(landmarks, 15)  # Left wrist\n",
    "    p16 = get_coordinates_safe(landmarks, 16)  # Right wrist\n",
    "    x_distance, y_distance = calculate_xy_distance(p15, p16)\n",
    "    angles.extend([x_distance, y_distance])  # Append x and y distance to the feature list\n",
    "    \n",
    "    return angles\n",
    "\n",
    "def calulating_percentage(avg , all_classes):\n",
    "    individual_threshold = {\n",
    "    'clean':0.3, 'happy':0.32, 'high': 0.55, 'loud': 0.90, 'quiet':0.9,\n",
    "     'sad':0.6, 'deep':0.5, 'soft':0.5, 'weak':0.6, 'flat': 0.27,\n",
    "   'expensive':0.27,  'poot':0.35,  'slow':0.5,  'thick':0.7\n",
    "    }\n",
    "    threshold_pecentage = []\n",
    "    for i,j in zip(avg,all_classes):\n",
    "        value=individual_threshold[j.lower()]\n",
    "        threshold_pecentage.append(i*100/value)\n",
    "    return threshold_pecentage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enssemble \n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB for MediaPipe processing\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image_rgb)\n",
    "    results_pose = pose.process(image_rgb)\n",
    "\n",
    "    # Initialize predictions and probabilities\n",
    "    left_prediction, right_prediction, pose_prediction = None, None, None\n",
    "    left_probs, right_probs, pose_probs = None, None, None\n",
    "\n",
    "    # Process hand landmarks (for both left and right hands)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
    "            label = handedness.classification[0].label\n",
    "            features = extract_features(hand_landmarks.landmark, results_pose.pose_landmarks.landmark if results_pose.pose_landmarks else [])\n",
    "\n",
    "            if label == 'Left':\n",
    "                left_prediction = left_model.predict([features])[0]\n",
    "                left_probs = left_model.predict_proba([features])[0]\n",
    "            elif label == 'Right':\n",
    "                right_prediction = right_model.predict([features])[0]\n",
    "                right_probs = right_model.predict_proba([features])[0]\n",
    "\n",
    "            # Draw hand landmarks\n",
    "            mp.solutions.drawing_utils.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Process pose landmarks\n",
    "    if results_pose.pose_landmarks:\n",
    "        mp.solutions.drawing_utils.draw_landmarks(frame, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        pose_landmarks = results_pose.pose_landmarks.landmark\n",
    "        pose_features = extract_pose_features(frame, pose_landmarks)  # Pass both frame and pose_landmarks\n",
    "        pose_prediction = pose_model.predict([pose_features])[0]\n",
    "        pose_probs = pose_model.predict_proba([pose_features])[0]\n",
    "\n",
    "    # Initialize the combined prediction logic\n",
    "    if left_prediction is not None and right_prediction is not None and pose_prediction is not None:\n",
    "        # All three detected, combine their probabilities\n",
    "        all_classes = sorted(set(left_model.classes_).union(set(right_model.classes_)).union(set(pose_model.classes_)))\n",
    "\n",
    "        # Align probabilities with all possible classes\n",
    "        left_prob_dict = {cls: prob for cls, prob in zip(left_model.classes_, left_probs)}\n",
    "        right_prob_dict = {cls: prob for cls, prob in zip(right_model.classes_, right_probs)}\n",
    "        pose_prob_dict = {cls: prob for cls, prob in zip(pose_model.classes_, pose_probs)}\n",
    "\n",
    "        left_probs_aligned = np.array([left_prob_dict.get(cls, 0) for cls in all_classes])*100\n",
    "        right_probs_aligned = np.array([right_prob_dict.get(cls, 0) for cls in all_classes])*100\n",
    "        pose_probs_aligned = np.array([pose_prob_dict.get(cls, 0) for cls in all_classes])*100\n",
    "\n",
    "        # Compute average probabilities\n",
    "        avg = (left_probs_aligned  + right_probs_aligned   + pose_probs_aligned) / 300\n",
    "        avg_probs = calulating_percentage(avg, all_classes)\n",
    "        # Find the class with the highest average probability\n",
    "        max_prob_index = np.argmax(avg_probs)\n",
    "        max_prob_class = all_classes[max_prob_index]\n",
    "\n",
    "        # Display the final prediction\n",
    "        cv2.putText(frame, f\"Final Prediction: {max_prob_class}, Prob: {avg_probs[max_prob_index]:.2f}\",\n",
    "                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        # Display the individual class probabilities\n",
    "        y_offset = 60  # Starting y position for probabilities display\n",
    "        for i, prob in enumerate(avg_probs):\n",
    "            class_name = all_classes[i]\n",
    "            cv2.putText(frame, f\"{class_name}: {prob:.2f}\", (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "            y_offset += 30  # Move down for the next class\n",
    "\n",
    "    else:\n",
    "        # Handle combinations when one or two parts are detected\n",
    "        prob_dicts = []\n",
    "        predictions = []\n",
    "        models = []\n",
    "        \n",
    "        # Add available predictions and probabilities\n",
    "        if left_prediction is not None:\n",
    "            prob_dicts.append(left_probs)\n",
    "            predictions.append(left_prediction)\n",
    "            models.append(left_model)\n",
    "        if right_prediction is not None:\n",
    "            prob_dicts.append(right_probs)\n",
    "            predictions.append(right_prediction)\n",
    "            models.append(right_model)\n",
    "        if pose_prediction is not None:\n",
    "            prob_dicts.append(pose_probs)\n",
    "            predictions.append(pose_prediction)\n",
    "            models.append(pose_model)\n",
    "\n",
    "        # If only one part detected, use that directly\n",
    "        if len(prob_dicts) == 1:\n",
    "            prob_dict = prob_dicts[0]\n",
    "            prediction = predictions[0]\n",
    "            model = models[0]\n",
    "            max_prob_index = np.argmax(prob_dict)\n",
    "            max_prob_class = model.classes_[max_prob_index]\n",
    "            cv2.putText(frame, f\"Final Prediction: {max_prob_class}, Prob: {prob_dict[max_prob_index]:.2f}\",\n",
    "                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        # If two parts are detected, average the probabilities\n",
    "        elif len(prob_dicts) == 2:\n",
    "            all_classes = sorted(set(models[0].classes_).union(set(models[1].classes_)))\n",
    "\n",
    "            # Align probabilities with all possible classes\n",
    "            prob_dict_1 = {cls: prob for cls, prob in zip(models[0].classes_, prob_dicts[0])}\n",
    "            prob_dict_2 = {cls: prob for cls, prob in zip(models[1].classes_, prob_dicts[1])}\n",
    "\n",
    "            probs_aligned_1 = np.array([prob_dict_1.get(cls, 0) for cls in all_classes])\n",
    "            probs_aligned_2 = np.array([prob_dict_2.get(cls, 0) for cls in all_classes])\n",
    "\n",
    "            # Compute average probabilities\n",
    "            avg = (probs_aligned_1 + probs_aligned_2) / 2\n",
    "            avg_probs = calulating_percentage(avg, all_classes)\n",
    "            \n",
    "            # Find the class with the highest average probability\n",
    "            max_prob_index = np.argmax(avg_probs)\n",
    "            max_prob_class = all_classes[max_prob_index]\n",
    "\n",
    "            # Display the final prediction\n",
    "            cv2.putText(frame, f\"Final Prediction: {max_prob_class}, Prob: {avg_probs[max_prob_index]:.2f}\",\n",
    "                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "            # Optionally, display individual probabilities for combined cases\n",
    "            y_offset = 60  # Starting y position for probabilities display\n",
    "            for i, prob in enumerate(avg_probs):\n",
    "                class_name = all_classes[i]\n",
    "                cv2.putText(frame, f\"{class_name}: {prob:.2f}\", (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "                y_offset += 30  # Move down for the next class\n",
    "\n",
    "    # Show the result\n",
    "    cv2.imshow(\"Hand and Pose Tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture object\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m image_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m      9\u001b[0m results \u001b[38;5;241m=\u001b[39m hands\u001b[38;5;241m.\u001b[39mprocess(image_rgb)\n\u001b[1;32m---> 10\u001b[0m results_pose \u001b[38;5;241m=\u001b[39m \u001b[43mpose\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_rgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Initialize predictions and probabilities for left hand and pose\u001b[39;00m\n\u001b[0;32m     13\u001b[0m left_prediction, pose_prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tarnished\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mediapipe\\python\\solutions\\pose.py:185\u001b[0m, in \u001b[0;36mPose.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    165\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tarnished\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mediapipe\\python\\solution_base.py:340\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    336\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    337\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    338\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Only Left hand and pose\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB for MediaPipe processing\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image_rgb)\n",
    "    results_pose = pose.process(image_rgb)\n",
    "\n",
    "    # Initialize predictions and probabilities for left hand and pose\n",
    "    left_prediction, pose_prediction = None, None\n",
    "    left_probs, pose_probs = None, None\n",
    "\n",
    "    # Process left hand landmarks\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
    "            label = handedness.classification[0].label\n",
    "            if label == 'Left':\n",
    "                features = extract_features(hand_landmarks.landmark, results_pose.pose_landmarks.landmark if results_pose.pose_landmarks else [])\n",
    "\n",
    "                left_prediction = left_model.predict([features])[0]\n",
    "                left_probs = left_model.predict_proba([features])[0]\n",
    "\n",
    "                # Draw left hand landmarks\n",
    "                mp.solutions.drawing_utils.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Process pose landmarks\n",
    "    if results_pose.pose_landmarks:\n",
    "        mp.solutions.drawing_utils.draw_landmarks(frame, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        pose_landmarks = results_pose.pose_landmarks.landmark\n",
    "        pose_features = extract_pose_features(frame, pose_landmarks)  # Pass both frame and pose_landmarks\n",
    "        pose_prediction = pose_model.predict([pose_features])[0]\n",
    "        pose_probs = pose_model.predict_proba([pose_features])[0]\n",
    "\n",
    "    # Initialize the combined prediction logic for left hand and pose\n",
    "    if left_prediction is not None and pose_prediction is not None:\n",
    "        # Both left hand and pose detected, combine their probabilities\n",
    "        all_classes = sorted(set(left_model.classes_).union(set(pose_model.classes_)))\n",
    "\n",
    "        # Align probabilities with all possible classes\n",
    "        left_prob_dict = {cls: prob for cls, prob in zip(left_model.classes_, left_probs)}\n",
    "        pose_prob_dict = {cls: prob for cls, prob in zip(pose_model.classes_, pose_probs)}\n",
    "\n",
    "        left_probs_aligned = np.array([left_prob_dict.get(cls, 0) for cls in all_classes])*100\n",
    "        pose_probs_aligned = np.array([pose_prob_dict.get(cls, 0) for cls in all_classes])*100\n",
    "\n",
    "        # Compute average probabilities\n",
    "        avg_probs = (left_probs_aligned + pose_probs_aligned*1.5) / 250\n",
    "\n",
    "        # Find the class with the highest average probability\n",
    "        max_prob_index = np.argmax(avg_probs)\n",
    "        max_prob_class = all_classes[max_prob_index]\n",
    "\n",
    "        # Display the final prediction\n",
    "        cv2.putText(frame, f\"Final Prediction: {max_prob_class}, Prob: {avg_probs[max_prob_index]:.2f}\",\n",
    "                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        # Display the individual class probabilities\n",
    "        y_offset = 60  # Starting y position for probabilities display\n",
    "        for i, prob in enumerate(avg_probs):\n",
    "            class_name = all_classes[i]\n",
    "            cv2.putText(frame, f\"{class_name}: {prob:.2f}\", (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
    "            y_offset += 30  # Move down for the next class\n",
    "\n",
    "    else:\n",
    "        # Handle combinations when only left hand or pose is detected\n",
    "        prob_dicts = []\n",
    "        predictions = []\n",
    "        models = []\n",
    "        \n",
    "        # Add available predictions and probabilities\n",
    "        if left_prediction is not None:\n",
    "            prob_dicts.append(left_probs)\n",
    "            predictions.append(left_prediction)\n",
    "            models.append(left_model)\n",
    "        if pose_prediction is not None:\n",
    "            prob_dicts.append(pose_probs)\n",
    "            predictions.append(pose_prediction)\n",
    "            models.append(pose_model)\n",
    "\n",
    "        # If only one part detected, use that directly\n",
    "        if len(prob_dicts) == 1:\n",
    "            prob_dict = prob_dicts[0]\n",
    "            prediction = predictions[0]\n",
    "            model = models[0]\n",
    "            max_prob_index = np.argmax(prob_dict)\n",
    "            max_prob_class = model.classes_[max_prob_index]\n",
    "            cv2.putText(frame, f\"Final Prediction: {max_prob_class}, Prob: {prob_dict[max_prob_index]:.2f}\",\n",
    "                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        # If both parts (left hand and pose) are detected, average the probabilities\n",
    "        elif len(prob_dicts) == 2:\n",
    "            all_classes = sorted(set(models[0].classes_).union(set(models[1].classes_)))\n",
    "\n",
    "            # Align probabilities with all possible classes\n",
    "            prob_dict_1 = {cls: prob for cls, prob in zip(models[0].classes_, prob_dicts[0])}\n",
    "            prob_dict_2 = {cls: prob for cls, prob in zip(models[1].classes_, prob_dicts[1])}\n",
    "\n",
    "            probs_aligned_1 = np.array([prob_dict_1.get(cls, 0) for cls in all_classes])\n",
    "            probs_aligned_2 = np.array([prob_dict_2.get(cls, 0) for cls in all_classes])\n",
    "\n",
    "            # Compute average probabilities\n",
    "            avg_probs = (probs_aligned_1 + probs_aligned_2) / 2\n",
    "\n",
    "            # Find the class with the highest average probability\n",
    "            max_prob_index = np.argmax(avg_probs)\n",
    "            max_prob_class = all_classes[max_prob_index]\n",
    "\n",
    "            # Display the final prediction\n",
    "            cv2.putText(frame, f\"Final Prediction: {max_prob_class}, Prob: {avg_probs[max_prob_index]:.2f}\",\n",
    "                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "            # Optionally, display individual probabilities for combined cases\n",
    "            y_offset = 60  # Starting y position for probabilities display\n",
    "            for i, prob in enumerate(avg_probs):\n",
    "                class_name = all_classes[i]\n",
    "                cv2.putText(frame, f\"{class_name}: {prob:.2f}\", (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
    "                y_offset += 30  # Move down for the next class\n",
    "\n",
    "    # Show the result\n",
    "    cv2.imshow(\"Left Hand and Pose Tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture object\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 frames\n",
    "def calulating_percentage(avg, all_classes):\n",
    "    individual_threshold = {\n",
    "        'clean': 0.3, 'happy': 0.32, 'high': 0.55, 'loud': 0.80, 'quiet': 0.9,\n",
    "        'sad': 0.6, 'deep': 0.5, 'soft': 0.5, 'weak': 0.6, 'flat': 0.30,\n",
    "        'expensive': 0.27, 'poot': 0.35, 'slow': 0.6, 'thick': 0.7\n",
    "    }\n",
    "    \n",
    "    threshold_percentage = []\n",
    "    for i, j in zip(avg, all_classes):\n",
    "        value = individual_threshold[j.lower()]\n",
    "        threshold_percentage.append(i * 100 / value)\n",
    "    return threshold_percentage\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create a dictionary to accumulate the probabilities for 10 frames\n",
    "frame_count = 0\n",
    "accumulated_probs = None\n",
    "final_prediction_text = \"\"\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB for MediaPipe processing\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image_rgb)\n",
    "    results_pose = pose.process(image_rgb)\n",
    "\n",
    "    # Initialize predictions and probabilities\n",
    "    left_prediction, right_prediction, pose_prediction = None, None, None\n",
    "    left_probs, right_probs, pose_probs = None, None, None\n",
    "    left_normal_direction = -1\n",
    "    # Process hand landmarks (for both left and right hands)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
    "            label = handedness.classification[0].label\n",
    "            features = extract_features(hand_landmarks.landmark, results_pose.pose_landmarks.landmark if results_pose.pose_landmarks else [])\n",
    "\n",
    "            if label == 'Left':\n",
    "                left_prediction = left_model.predict([features])[0]\n",
    "                left_probs = left_model.predict_proba([features])[0]\n",
    "            elif label == 'Right':\n",
    "                right_prediction = right_model.predict([features])[0]\n",
    "                right_probs = right_model.predict_proba([features])[0]\n",
    "\n",
    "            # Draw hand landmarks\n",
    "            mp.solutions.drawing_utils.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Process pose landmarks\n",
    "    if results_pose.pose_landmarks:\n",
    "        mp.solutions.drawing_utils.draw_landmarks(frame, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        pose_landmarks = results_pose.pose_landmarks.landmark\n",
    "        pose_features = extract_pose_features(frame, pose_landmarks)  # Pass both frame and pose_landmarks\n",
    "        pose_prediction = pose_model.predict([pose_features])[0]\n",
    "        pose_probs = pose_model.predict_proba([pose_features])[0]\n",
    "\n",
    "    # Initialize the combined prediction logic\n",
    "    if left_prediction is not None and right_prediction is not None and pose_prediction is not None:\n",
    "        # All three detected, combine their probabilities\n",
    "        all_classes = sorted(set(left_model.classes_).union(set(right_model.classes_)).union(set(pose_model.classes_)))\n",
    "\n",
    "        # Align probabilities with all possible classes\n",
    "        left_prob_dict = {cls: prob for cls, prob in zip(left_model.classes_, left_probs)}\n",
    "        right_prob_dict = {cls: prob for cls, prob in zip(right_model.classes_, right_probs)}\n",
    "        pose_prob_dict = {cls: prob for cls, prob in zip(pose_model.classes_, pose_probs)}\n",
    "\n",
    "        left_probs_aligned = np.array([left_prob_dict.get(cls, 0) for cls in all_classes]) * 100\n",
    "        right_probs_aligned = np.array([right_prob_dict.get(cls, 0) for cls in all_classes]) * 100\n",
    "        pose_probs_aligned = np.array([pose_prob_dict.get(cls, 0) for cls in all_classes]) * 100\n",
    "\n",
    "        # Compute average probabilities\n",
    "        avg = (left_probs_aligned + right_probs_aligned + pose_probs_aligned) / 300\n",
    "        avg_probs = calulating_percentage(avg, all_classes)\n",
    "\n",
    "        # If accumulated_probs is None, initialize it\n",
    "        if accumulated_probs is None:\n",
    "            accumulated_probs = np.zeros_like(avg_probs)\n",
    "\n",
    "        # Accumulate the probabilities over 10 frames\n",
    "        accumulated_probs += avg_probs\n",
    "        frame_count += 1\n",
    "\n",
    "        if frame_count == 10:\n",
    "            # After 10 frames, find the class with the highest accumulated probability\n",
    "            max_prob_index = np.argmax(accumulated_probs)\n",
    "            max_prob_class = all_classes[max_prob_index]\n",
    "            \n",
    "            # Store the final prediction text\n",
    "            final_prediction_text = f\"Final Prediction: {max_prob_class}, Prob: {accumulated_probs[max_prob_index]:.2f}\"\n",
    "\n",
    "            # Reset accumulated_probs for the next cycle\n",
    "            accumulated_probs = None\n",
    "            frame_count = 0\n",
    "\n",
    "    # Display the final prediction permanently on the screen\n",
    "    if final_prediction_text:\n",
    "        cv2.putText(frame, final_prediction_text,\n",
    "                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    # Optionally, display individual probabilities for combined cases\n",
    "    if accumulated_probs is not None:\n",
    "        y_offset = 60  # Starting y position for probabilities display\n",
    "        for i, prob in enumerate(accumulated_probs):\n",
    "            class_name = all_classes[i]\n",
    "            cv2.putText(frame, f\"{class_name}: {prob:.2f}\", (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "            y_offset += 30  # Move down for the next class\n",
    "\n",
    "    # Show the result\n",
    "    cv2.imshow(\"Hand and Pose Tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture object\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 1828/1828 [03:50<00:00,  7.82image/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize variables to store the ground truth and predicted labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Define the folder containing the dataset\n",
    "data_folder = 'D:/Test-3/Test_data2'\n",
    "\n",
    "# Get all the class names from the dataset\n",
    "all_classes = sorted(os.listdir(data_folder))\n",
    "num_classes = len(all_classes)\n",
    "\n",
    "# Initialize progress bar for dataset processing\n",
    "total_images = sum([len(os.listdir(os.path.join(data_folder, label))) for label in all_classes])\n",
    "progress_bar = tqdm(total=total_images, desc=\"Processing Images\", unit=\"image\")\n",
    "\n",
    "# Initialize accuracy tracking for each class\n",
    "class_correct = {cls: 0 for cls in all_classes}\n",
    "class_total = {cls: 0 for cls in all_classes}\n",
    "\n",
    "# Start processing each image\n",
    "for label in all_classes:\n",
    "    class_folder = os.path.join(data_folder, label)\n",
    "    \n",
    "    if os.path.isdir(class_folder):\n",
    "        # Iterate through images in each class folder\n",
    "        for image_name in os.listdir(class_folder):\n",
    "            image_path = os.path.join(class_folder, image_name)\n",
    "            \n",
    "            # Read the image\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            # Convert image to RGB\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(image_rgb)\n",
    "            \n",
    "            # Process pose landmarks\n",
    "            image_pose_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            pose_results = pose.process(image_pose_rgb)\n",
    "            \n",
    "            # Initialize predictions and probabilities\n",
    "            left_prediction, right_prediction, pose_prediction = None, None, None\n",
    "            left_probs, right_probs, pose_probs = None, None, None\n",
    "\n",
    "            # Process hand landmarks (for both left and right hands)\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
    "                    label = handedness.classification[0].label\n",
    "                    features = extract_features(hand_landmarks.landmark, pose_results.pose_landmarks.landmark if pose_results.pose_landmarks else [])\n",
    "\n",
    "                    if label == 'Left':\n",
    "                        left_prediction = left_model.predict([features])[0]\n",
    "                        left_probs = left_model.predict_proba([features])[0]\n",
    "                    elif label == 'Right':\n",
    "                        right_prediction = right_model.predict([features])[0]\n",
    "                        right_probs = right_model.predict_proba([features])[0]\n",
    "\n",
    "            # Process pose landmarks\n",
    "            if pose_results.pose_landmarks:\n",
    "                pose_landmarks = pose_results.pose_landmarks.landmark\n",
    "                pose_features = extract_pose_features(image, pose_landmarks)\n",
    "                pose_prediction = pose_model.predict([pose_features])[0]\n",
    "                pose_probs = pose_model.predict_proba([pose_features])[0]\n",
    "\n",
    "\n",
    "            if pose_results.pose_landmarks and not results.multi_hand_landmarks:\n",
    "                # Only Pose landmarks are available\n",
    "                y_true.append(label)  # True label is the folder name (the class)\n",
    "                y_pred.append(pose_prediction)  # Predict based on Pose only\n",
    "\n",
    "            elif results.multi_hand_landmarks and not pose_results.pose_landmarks:\n",
    "                # Only Hand landmarks are available (Left or Right)\n",
    "                if left_prediction is not None:\n",
    "                    y_true.append(label)  # True label is the folder name (the class)\n",
    "                    y_pred.append(left_prediction)  # Predict based on Left Hand only\n",
    "                elif right_prediction is not None:\n",
    "                    y_true.append(label)  # True label is the folder name (the class)\n",
    "                    y_pred.append(right_prediction)  # Predict based on Right Hand only\n",
    "\n",
    "            elif results.multi_hand_landmarks and pose_results.pose_landmarks:\n",
    "                # Both Hand and Pose landmarks are available\n",
    "                if left_prediction is not None and right_prediction is not None:\n",
    "                    # Both Left and Right Hand and Pose are available\n",
    "                    all_classes_sorted = sorted(set(left_model.classes_).union(set(right_model.classes_)).union(set(pose_model.classes_)))\n",
    "\n",
    "                    # Align probabilities with all possible classes\n",
    "                    left_prob_dict = {cls: prob for cls, prob in zip(left_model.classes_, left_probs)}\n",
    "                    right_prob_dict = {cls: prob for cls, prob in zip(right_model.classes_, right_probs)}\n",
    "                    pose_prob_dict = {cls: prob for cls, prob in zip(pose_model.classes_, pose_probs)}\n",
    "\n",
    "                    left_probs_aligned = np.array([left_prob_dict.get(cls, 0) for cls in all_classes_sorted])\n",
    "                    right_probs_aligned = np.array([right_prob_dict.get(cls, 0) for cls in all_classes_sorted])\n",
    "                    pose_probs_aligned = np.array([pose_prob_dict.get(cls, 0) for cls in all_classes_sorted])\n",
    "\n",
    "                    # Compute average probabilities\n",
    "                    avg_probs = (left_probs_aligned * 1.2 + right_probs_aligned / 1.2 + pose_probs_aligned) / 3\n",
    "\n",
    "                    # Find the class with the highest average probability\n",
    "                    max_prob_index = np.argmax(avg_probs)\n",
    "                    max_prob_class = all_classes_sorted[max_prob_index]\n",
    "\n",
    "                    y_true.append(label)  # True label is the folder name (the class)\n",
    "                    y_pred.append(max_prob_class)  # Predicted label\n",
    "\n",
    "                elif left_prediction is not None and pose_prediction is not None:\n",
    "                    # Only Left Hand and Pose available\n",
    "                    all_classes_sorted = sorted(set(left_model.classes_).union(set(pose_model.classes_)))\n",
    "\n",
    "                    left_prob_dict = {cls: prob for cls, prob in zip(left_model.classes_, left_probs)}\n",
    "                    pose_prob_dict = {cls: prob for cls, prob in zip(pose_model.classes_, pose_probs)}\n",
    "\n",
    "                    left_probs_aligned = np.array([left_prob_dict.get(cls, 0) for cls in all_classes_sorted])\n",
    "                    pose_probs_aligned = np.array([pose_prob_dict.get(cls, 0) for cls in all_classes_sorted])\n",
    "\n",
    "                    avg_probs = (left_probs_aligned + pose_probs_aligned) / 2\n",
    "                    max_prob_index = np.argmax(avg_probs)\n",
    "                    max_prob_class = all_classes_sorted[max_prob_index]\n",
    "\n",
    "                    y_true.append(label)\n",
    "                    y_pred.append(max_prob_class)\n",
    "\n",
    "                elif right_prediction is not None and pose_prediction is not None:\n",
    "                    # Only Right Hand and Pose available\n",
    "                    all_classes_sorted = sorted(set(right_model.classes_).union(set(pose_model.classes_)))\n",
    "\n",
    "                    right_prob_dict = {cls: prob for cls, prob in zip(right_model.classes_, right_probs)}\n",
    "                    pose_prob_dict = {cls: prob for cls, prob in zip(pose_model.classes_, pose_probs)}\n",
    "\n",
    "                    right_probs_aligned = np.array([right_prob_dict.get(cls, 0) for cls in all_classes_sorted])\n",
    "                    pose_probs_aligned = np.array([pose_prob_dict.get(cls, 0) for cls in all_classes_sorted])\n",
    "\n",
    "                    avg_probs = (right_probs_aligned + pose_probs_aligned) / 2\n",
    "                    max_prob_index = np.argmax(avg_probs)\n",
    "                    max_prob_class = all_classes_sorted[max_prob_index]\n",
    "\n",
    "                    y_true.append(label)\n",
    "                    y_pred.append(max_prob_class)\n",
    "\n",
    "            # Update the progress bar\n",
    "            progress_bar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tarnished\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Tarnished\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Tarnished\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Processing Images: 100%|██████████| 1828/1828 [04:05<00:00,  7.44image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Accuracy: 0.00\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Poot       0.00      0.00      0.00         1\n",
      "       Quiet       0.00      0.00      0.00         0\n",
      "         Sad       0.00      0.00      0.00         0\n",
      "        Slow       0.00      0.00      0.00         0\n",
      "        Soft       0.00      1.00      0.01         1\n",
      "       Thick       0.00      1.00      0.01         1\n",
      "        Weak       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.00      0.67      0.00         3\n",
      "   macro avg       0.00      0.29      0.00         3\n",
      "weighted avg       0.00      0.67      0.00         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\nOverall Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred, labels=all_classes)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_true, y_pred, target_names=all_classes, labels=all_classes)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Finish progress bar\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enssemble \n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB for MediaPipe processing\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image_rgb)\n",
    "    results_pose = pose.process(image_rgb)\n",
    "\n",
    "    # Initialize predictions and probabilities\n",
    "    left_prediction, right_prediction, pose_prediction = None, None, None\n",
    "    left_probs, right_probs, pose_probs = None, None, None\n",
    "\n",
    "    # Process hand landmarks (for both left and right hands)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
    "            label = handedness.classification[0].label\n",
    "            features = extract_features(hand_landmarks.landmark, results_pose.pose_landmarks.landmark if results_pose.pose_landmarks else [])\n",
    "\n",
    "            if label == 'Left':\n",
    "                left_prediction = left_model.predict([features])[0]\n",
    "                left_probs = left_model.predict_proba([features])[0]\n",
    "            elif label == 'Right':\n",
    "                right_prediction = right_model.predict([features])[0]\n",
    "                right_probs = right_model.predict_proba([features])[0]\n",
    "\n",
    "            # Draw hand landmarks\n",
    "            mp.solutions.drawing_utils.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Process pose landmarks\n",
    "    if results_pose.pose_landmarks:\n",
    "        mp.solutions.drawing_utils.draw_landmarks(frame, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        pose_landmarks = results_pose.pose_landmarks.landmark\n",
    "        pose_features = extract_pose_features(frame, pose_landmarks)  # Pass both frame and pose_landmarks\n",
    "        pose_prediction = pose_model.predict([pose_features])[0]\n",
    "        pose_probs = pose_model.predict_proba([pose_features])[0]\n",
    "\n",
    "    # Initialize the combined prediction logic\n",
    "    if left_prediction is not None and right_prediction is not None and pose_prediction is not None:\n",
    "        # All three detected, combine their probabilities\n",
    "        all_classes = sorted(set(left_model.classes_).union(set(right_model.classes_)).union(set(pose_model.classes_)))\n",
    "\n",
    "        # Align probabilities with all possible classes\n",
    "        left_prob_dict = {cls: prob for cls, prob in zip(left_model.classes_, left_probs)}\n",
    "        right_prob_dict = {cls: prob for cls, prob in zip(right_model.classes_, right_probs)}\n",
    "        pose_prob_dict = {cls: prob for cls, prob in zip(pose_model.classes_, pose_probs)}\n",
    "\n",
    "        left_probs_aligned = np.array([left_prob_dict.get(cls, 0) for cls in all_classes])*100\n",
    "        right_probs_aligned = np.array([right_prob_dict.get(cls, 0) for cls in all_classes])*100\n",
    "        pose_probs_aligned = np.array([pose_prob_dict.get(cls, 0) for cls in all_classes])*100\n",
    "\n",
    "        # Compute average probabilities\n",
    "        avg = (left_probs_aligned  + right_probs_aligned   + pose_probs_aligned) / 300\n",
    "        avg_probs = calulating_percentage(avg, all_classes)\n",
    "        # Find the class with the highest average probability\n",
    "        max_prob_index = np.argmax(avg_probs)\n",
    "        max_prob_class = all_classes[max_prob_index]\n",
    "\n",
    "        # Display the final prediction\n",
    "        cv2.putText(frame, f\"Final Prediction: {max_prob_class}, Prob: {avg_probs[max_prob_index]:.2f}\",\n",
    "                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        # Display the individual class probabilities\n",
    "        y_offset = 60  # Starting y position for probabilities display\n",
    "        for i, prob in enumerate(avg_probs):\n",
    "            class_name = all_classes[i]\n",
    "            cv2.putText(frame, f\"{class_name}: {prob:.2f}\", (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "            y_offset += 30  # Move down for the next class\n",
    "\n",
    "    else:\n",
    "        # Handle combinations when one or two parts are detected\n",
    "        prob_dicts = []\n",
    "        predictions = []\n",
    "        models = []\n",
    "        \n",
    "        # Add available predictions and probabilities\n",
    "        if left_prediction is not None:\n",
    "            prob_dicts.append(left_probs)\n",
    "            predictions.append(left_prediction)\n",
    "            models.append(left_model)\n",
    "        if right_prediction is not None:\n",
    "            prob_dicts.append(right_probs)\n",
    "            predictions.append(right_prediction)\n",
    "            models.append(right_model)\n",
    "        if pose_prediction is not None:\n",
    "            prob_dicts.append(pose_probs)\n",
    "            predictions.append(pose_prediction)\n",
    "            models.append(pose_model)\n",
    "\n",
    "        # If only one part detected, use that directly\n",
    "        if len(prob_dicts) == 1:\n",
    "            prob_dict = prob_dicts[0]\n",
    "            prediction = predictions[0]\n",
    "            model = models[0]\n",
    "            max_prob_index = np.argmax(prob_dict)\n",
    "            max_prob_class = model.classes_[max_prob_index]\n",
    "            cv2.putText(frame, f\"Final Prediction: {max_prob_class}, Prob: {prob_dict[max_prob_index]:.2f}\",\n",
    "                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        # If two parts are detected, average the probabilities\n",
    "        elif len(prob_dicts) == 2:\n",
    "            all_classes = sorted(set(models[0].classes_).union(set(models[1].classes_)))\n",
    "\n",
    "            # Align probabilities with all possible classes\n",
    "            prob_dict_1 = {cls: prob for cls, prob in zip(models[0].classes_, prob_dicts[0])}\n",
    "            prob_dict_2 = {cls: prob for cls, prob in zip(models[1].classes_, prob_dicts[1])}\n",
    "\n",
    "            probs_aligned_1 = np.array([prob_dict_1.get(cls, 0) for cls in all_classes])\n",
    "            probs_aligned_2 = np.array([prob_dict_2.get(cls, 0) for cls in all_classes])\n",
    "\n",
    "            # Compute average probabilities\n",
    "            avg = (probs_aligned_1 + probs_aligned_2) / 2\n",
    "            avg_probs = calulating_percentage(avg, all_classes)\n",
    "            \n",
    "            # Find the class with the highest average probability\n",
    "            max_prob_index = np.argmax(avg_probs)\n",
    "            max_prob_class = all_classes[max_prob_index]\n",
    "\n",
    "            # Display the final prediction\n",
    "            cv2.putText(frame, f\"Final Prediction: {max_prob_class}, Prob: {avg_probs[max_prob_index]:.2f}\",\n",
    "                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "            # Optionally, display individual probabilities for combined cases\n",
    "            y_offset = 60  # Starting y position for probabilities display\n",
    "            for i, prob in enumerate(avg_probs):\n",
    "                class_name = all_classes[i]\n",
    "                cv2.putText(frame, f\"{class_name}: {prob:.2f}\", (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "                y_offset += 30  # Move down for the next class\n",
    "\n",
    "    # Show the result\n",
    "    cv2.imshow(\"Hand and Pose Tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture object\n",
    "cap.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
